model_id,paper_id
pwc:model/retinanet,pwc:paper/multiple-instance-active-learning-for-object
pwc:model/ssd,pwc:paper/multiple-instance-active-learning-for-object
pwc:model/retinanet,pwc:paper/multiple-instance-active-learning-for-object
pwc:model/typiclust,pwc:paper/active-learning-on-a-budget-opposite
pwc:model/learning-loss,pwc:paper/190503677
pwc:model/coregcn,pwc:paper/sequential-graph-convolutional-network-for
pwc:model/core-set,pwc:paper/active-learning-for-convolutional-neural
pwc:model/random-baseline--resnet18-,pwc:paper/towards-robust-and-reproducible-active
pwc:model/random-baseline--vgg16-,pwc:paper/towards-robust-and-reproducible-active
pwc:model/akhcrnet,pwc:paper/akhcrnet-bengali-handwritten-character
pwc:model/khcr,pwc:paper/kurdish-handwritten-character-recognition
pwc:model/flor,pwc:paper/kohtd-kazakh-offline-handwritten-text-dataset
pwc:model/puigcerver,pwc:paper/kohtd-kazakh-offline-handwritten-text-dataset
pwc:model/abdallah,pwc:paper/kohtd-kazakh-offline-handwritten-text-dataset
pwc:model/bluche,pwc:paper/kohtd-kazakh-offline-handwritten-text-dataset
pwc:model/cnn,pwc:paper/effective-handwritten-digit-recognition-using
pwc:model/sign-symmetry,pwc:paper/how-important-is-weight-symmetry-in
pwc:model/i2l-nopool,pwc:paper/teaching-machines-to-code-neural-markup
pwc:model/i2l-strips,pwc:paper/teaching-machines-to-code-neural-markup
pwc:model/i2l-strips,pwc:paper/teaching-machines-to-code-neural-markup
pwc:model/attentionocr-inception-resnet-v2-location,pwc:paper/attention-based-extraction-of-structured
pwc:model/see,pwc:paper/see-towards-semi-supervisedend-to-end-scene
pwc:model/street,pwc:paper/end-to-end-interpretation-of-the-french
pwc:model/maskocr-l,pwc:paper/maskocr-text-recognition-with-masked-encoder
pwc:model/transocr,pwc:paper/scene-text-telescope-text-focused-scene-image
pwc:model/sar,pwc:paper/show-attend-and-read-a-simple-and-strong
pwc:model/crnn,pwc:paper/an-end-to-end-trainable-neural-network-for
pwc:model/srn,pwc:paper/towards-accurate-scene-text-recognition-with
pwc:model/aster,pwc:paper/aster-an-attentional-scene-text-recognizer
pwc:model/moran,pwc:paper/a-multi-object-rectified-attention-network
pwc:model/seed,pwc:paper/seed-semantics-enhanced-encoder-decoder
pwc:model/uformer-b,pwc:paper/uformer-a-general-u-shaped-transformer-for
pwc:model/restormer,pwc:paper/restormer-efficient-transformer-for-high
pwc:model/deeprft,pwc:paper/deep-residual-fourier-transformation-for
pwc:model/mprnet,pwc:paper/multi-stage-progressive-image-restoration
pwc:model/mssnet,pwc:paper/mssnet-multi-scale-stage-network-for-single
pwc:model/maxim,pwc:paper/maxim-multi-axis-mlp-for-image-processing
pwc:model/pan-et-al,pwc:paper/blind-image-deblurring-using-dark-channel
pwc:model/hu-et-al,pwc:paper/deblurring-low-light-images-with-light
pwc:model/dmphn,pwc:paper/deep-stacked-hierarchical-multi-patch-network
pwc:model/srn,pwc:paper/scale-recurrent-network-for-deep-image
pwc:model/zhang-et-al,pwc:paper/dynamic-scene-deblurring-using-spatially
pwc:model/deblurgan-v2,pwc:paper/deblurgan-v2-deblurring-orders-of-magnitude
pwc:model/xu-et-al,pwc:paper/unnatural-l0-sparse-representation-for
pwc:model/deblurgan,pwc:paper/deblurgan-blind-motion-deblurring-using
pwc:model/nah-et-al,pwc:paper/deep-multi-scale-convolutional-neural-network
pwc:model/vrt--gopro-,pwc:paper/vrt-a-video-restoration-transformer
pwc:model/vrt--reds-,pwc:paper/vrt-a-video-restoration-transformer
pwc:model/uformer-b,pwc:paper/uformer-a-general-u-shaped-transformer-for
pwc:model/deeprft-,pwc:paper/deep-residual-fourier-transformation-for
pwc:model/restormer,pwc:paper/restormer-efficient-transformer-for-high
pwc:model/maxim,pwc:paper/maxim-multi-axis-mlp-for-image-processing
pwc:model/mssnet,pwc:paper/mssnet-multi-scale-stage-network-for-single
pwc:model/mprnet,pwc:paper/multi-stage-progressive-image-restoration
pwc:model/deblurgan-v2,pwc:paper/deblurgan-v2-deblurring-orders-of-magnitude
pwc:model/srn,pwc:paper/scale-recurrent-network-for-deep-image
pwc:model/pan-et-al,pwc:paper/blind-image-deblurring-using-dark-channel
pwc:model/hu-et-al,pwc:paper/deblurring-low-light-images-with-light
pwc:model/deblurgan,pwc:paper/deblurgan-blind-motion-deblurring-using
pwc:model/rvrt,pwc:paper/recurrent-video-restoration-transformer-with
pwc:model/vrt,pwc:paper/vrt-a-video-restoration-transformer
pwc:model/fgst,pwc:paper/flow-guided-sparse-transformer-for-video
pwc:model/mb2d,pwc:paper/blur-more-to-deblur-better-multi-blur2deblur
pwc:model/stripformer,pwc:paper/stripformer-strip-transformer-for-fast-image
pwc:model/deeprft-,pwc:paper/deep-residual-fourier-transformation-for
pwc:model/mssnet,pwc:paper/mssnet-multi-scale-stage-network-for-single
pwc:model/banet,pwc:paper/banet-blur-aware-attention-networks-for
pwc:model/maxim,pwc:paper/maxim-multi-axis-mlp-for-image-processing
pwc:model/mprnet,pwc:paper/multi-stage-progressive-image-restoration
pwc:model/srn,pwc:paper/scale-recurrent-network-for-deep-image
pwc:model/deblurgan-v2,pwc:paper/deblurgan-v2-deblurring-orders-of-magnitude
pwc:model/maxim-3s,pwc:paper/maxim-multi-axis-mlp-for-image-processing
pwc:model/maxim,pwc:paper/maxim-multi-axis-mlp-for-image-processing
pwc:model/restormer-local,pwc:paper/revisiting-global-statistics-aggregation-for
pwc:model/deeprft-,pwc:paper/deep-residual-fourier-transformation-for
pwc:model/restormer,pwc:paper/restormer-efficient-transformer-for-high
pwc:model/mprnet-local,pwc:paper/revisiting-global-statistics-aggregation-for
pwc:model/stripformer,pwc:paper/stripformer-strip-transformer-for-fast-image
pwc:model/mprnet,pwc:paper/multi-stage-progressive-image-restoration
pwc:model/uformer-b,pwc:paper/uformer-a-general-u-shaped-transformer-for
pwc:model/banet,pwc:paper/banet-blur-aware-attention-networks-for
pwc:model/mt-rnn,pwc:paper/multi-temporal-recurrent-neural-networks-for
pwc:model/dmphn,pwc:paper/deep-stacked-hierarchical-multi-patch-network
pwc:model/dbgan,pwc:paper/deblurring-by-realistic-blurring
pwc:model/srn,pwc:paper/scale-recurrent-network-for-deep-image
pwc:model/nah-et-al,pwc:paper/deep-multi-scale-convolutional-neural-network
pwc:model/nafnet--reds-,pwc:paper/simple-baselines-for-image-restoration
pwc:model/vrt--gopro-,pwc:paper/vrt-a-video-restoration-transformer
pwc:model/vrt--reds-,pwc:paper/vrt-a-video-restoration-transformer
pwc:model/deblurgan-inception,pwc:paper/deblurgan-v2-deblurring-orders-of-magnitude
pwc:model/maxim--reds-,pwc:paper/maxim-multi-axis-mlp-for-image-processing
pwc:model/deeprft--gopro-,pwc:paper/deep-residual-fourier-transformation-for
pwc:model/deeprft--reds-,pwc:paper/deep-residual-fourier-transformation-for
pwc:model/mpr-local,pwc:paper/revisiting-global-statistics-aggregation-for
pwc:model/maxim--gopro-,pwc:paper/maxim-multi-axis-mlp-for-image-processing
pwc:model/restormer-local,pwc:paper/restormer-efficient-transformer-for-high
pwc:model/restormer,pwc:paper/restormer-efficient-transformer-for-high
pwc:model/vrt,pwc:paper/vrt-a-video-restoration-transformer
pwc:model/edvr-deblur,pwc:paper/edvr-video-restoration-with-enhanced
