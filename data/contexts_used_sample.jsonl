{"id": "uxv:context/1806.06827-SVM-703-906", "type": "context", "paper_arxiv_id": "1806.06827", "paper_pwc_id": "pwc:paper/pac-bayes-bounds-for-stable-algorithms-with", "entity_id": "pwc:method/svm", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [803, 806], "context_offset_in_paper": [703, 906], "context": "ed algorithm in terms of the hypothesis stability coefficients. We also provide a new bound for the SVM classifier, which is compared to other known bounds experimentally. Ours appears to be the first st"}
{"id": "uxv:context/1806.06827-SVM-2872-3075", "type": "context", "paper_arxiv_id": "1806.06827", "paper_pwc_id": "pwc:paper/pac-bayes-bounds-for-stable-algorithms-with", "entity_id": "pwc:method/svm", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [2972, 2975], "context_offset_in_paper": [2872, 3075], "context": "e6d49ace3c}}, {{cite:2d13a8d5-5b16-4084-a531-63beee1da217}}\nwe deduce a concentration bound for the SVM weight vector,\nand also a PAC-Bayes performance bound for SVM with Gaussian randomization.\nExperime"}
{"id": "uxv:context/1806.06827-SVM-2934-3137", "type": "context", "paper_arxiv_id": "1806.06827", "paper_pwc_id": "pwc:paper/pac-bayes-bounds-for-stable-algorithms-with", "entity_id": "pwc:method/svm", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [3034, 3037], "context_offset_in_paper": [2934, 3137], "context": " deduce a concentration bound for the SVM weight vector,\nand also a PAC-Bayes performance bound for SVM with Gaussian randomization.\nExperimental results compare our new bound with other stability-based "}
{"id": "uxv:context/1806.06827-SVM-10361-10564", "type": "context", "paper_arxiv_id": "1806.06827", "paper_pwc_id": "pwc:paper/pac-bayes-bounds-for-stable-algorithms-with", "entity_id": "pwc:method/svm", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [10461, 10464], "context_offset_in_paper": [10361, 10564], "context": "337-4cdd-a55d-2e27accbc389}}, {{cite:f4448309-7e95-4e18-b8a0-1e1d848f1b02}}.\n\nA PAC-Bayes bound for SVM with Gaussian randomization\nFor a Support Vector Machine (SVM) with feature map FORMULA \ninto a sep"}
{"id": "uxv:context/1806.06827-SVM-10423-10626", "type": "context", "paper_arxiv_id": "1806.06827", "paper_pwc_id": "pwc:paper/pac-bayes-bounds-for-stable-algorithms-with", "entity_id": "pwc:method/svm", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [10523, 10526], "context_offset_in_paper": [10423, 10626], "context": "e1d848f1b02}}.\n\nA PAC-Bayes bound for SVM with Gaussian randomization\nFor a Support Vector Machine (SVM) with feature map FORMULA \ninto a separable Hilbert space FORMULA ,\nwe may\nidentifyRiesz representa"}
{"id": "uxv:context/1806.06827-SVM-10665-10868", "type": "context", "paper_arxiv_id": "1806.06827", "paper_pwc_id": "pwc:paper/pac-bayes-bounds-for-stable-algorithms-with", "entity_id": "pwc:method/svm", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [10765, 10768], "context_offset_in_paper": [10665, 10868], "context": "ion.\na linear classifier FORMULA \nwith a vector FORMULA . With this identification we can regard an SVM as a\nHilbert spaceFORMULA  may be infinite-dimensional (e.g. Gaussian kernel).\nvalued mapping\nthat "}
{"id": "uxv:context/1806.06827-SVM-10871-11074", "type": "context", "paper_arxiv_id": "1806.06827", "paper_pwc_id": "pwc:paper/pac-bayes-bounds-for-stable-algorithms-with", "entity_id": "pwc:method/svm", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [10971, 10974], "context_offset_in_paper": [10871, 11074], "context": "ed on a training sample FORMULA  learns a weight vector\nFORMULA .\nIn this context, stability of the SVM's solution\nthen reduces to stability of the learned weight vector.\nTo be specific, let FORMULA  be "}
{"id": "uxv:context/1806.06827-SVM-10978-11181", "type": "context", "paper_arxiv_id": "1806.06827", "paper_pwc_id": "pwc:paper/pac-bayes-bounds-for-stable-algorithms-with", "entity_id": "pwc:method/svm", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [11078, 11081], "context_offset_in_paper": [10978, 11181], "context": "olution\nthen reduces to stability of the learned weight vector.\nTo be specific, let FORMULA  be the SVM\nthat regularizes the empirical risk over the sample FORMULA \nby solving the following optimization "}
{"id": "uxv:context/1806.06827-SVM-11331-11534", "type": "context", "paper_arxiv_id": "1806.06827", "paper_pwc_id": "pwc:paper/pac-bayes-bounds-for-stable-algorithms-with", "entity_id": "pwc:method/svm", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [11431, 11434], "context_offset_in_paper": [11331, 11534], "context": " setting).\nThen a direct application of our thm:main\ntogether with a concentration argument for the SVM weight vector\n(see our concentration-SVM below)\ngives the following:\nCorollary 3 \nLet FORMULA .\nSup"}
{"id": "uxv:context/1806.06827-SVM-11372-11575", "type": "context", "paper_arxiv_id": "1806.06827", "paper_pwc_id": "pwc:paper/pac-bayes-bounds-for-stable-algorithms-with", "entity_id": "pwc:method/svm", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [11472, 11475], "context_offset_in_paper": [11372, 11575], "context": "ur thm:main\ntogether with a concentration argument for the SVM weight vector\n(see our concentration-SVM below)\ngives the following:\nCorollary 3 \nLet FORMULA .\nSuppose that (once trained) the algorithm wi"}
{"id": "uxv:context/1806.06827-SVM-11986-12189", "type": "context", "paper_arxiv_id": "1806.06827", "paper_pwc_id": "pwc:paper/pac-bayes-bounds-for-stable-algorithms-with", "entity_id": "pwc:method/svm", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [12086, 12089], "context_offset_in_paper": [11986, 12189], "context": "overs any regularized ERM algorithm\n{{cite:8f445e6b-b58f-4865-b8ea-0389cab72565}}.\nWe applied it to SVM's whose hypothesis sensitivity coefficients\n(as in our def:hyp-stab) are known.\nIt can be argued th"}
{"id": "uxv:context/1806.06827-SVM-13240-13443", "type": "context", "paper_arxiv_id": "1806.06827", "paper_pwc_id": "pwc:paper/pac-bayes-bounds-for-stable-algorithms-with", "entity_id": "pwc:method/svm", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [13340, 13343], "context_offset_in_paper": [13240, 13443], "context": "joys boundedness and Lipschitz continuity.\nP@EW: Our new instance-dependent PAC-Bayes bound\nOur pbb-SVM,\nwith FORMULA ,\na Gaussian centered at FORMULA \nwith randomization variance FORMULA ,\ngives the fol"}
{"id": "uxv:context/1806.06827-SVM-14591-14794", "type": "context", "paper_arxiv_id": "1806.06827", "paper_pwc_id": "pwc:paper/pac-bayes-bounds-for-stable-algorithms-with", "entity_id": "pwc:method/svm", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [14691, 14694], "context_offset_in_paper": [14591, 14794], "context": "ernel) and FORMULA  (clipped hinge loss).\nIn app:SVMformulations below there is a list of different SVM formulations,\nand how to convert between them. We found it useful when implementing code for experi"}
{"id": "uxv:context/1806.06827-SVM-15853-16056", "type": "context", "paper_arxiv_id": "1806.06827", "paper_pwc_id": "pwc:paper/pac-bayes-bounds-for-stable-algorithms-with", "entity_id": "pwc:method/svm", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [15953, 15956], "context_offset_in_paper": [15853, 16056], "context": "arger values of FORMULA , which in turn penalize the norm of the weight vector\nof the corresponding SVM, resulting in a small first term in P@O bound.\nNote that P@O bound is equivalent\nto the setting of "}
{"id": "uxv:context/1806.06827-SVM-16308-16511", "type": "context", "paper_arxiv_id": "1806.06827", "paper_pwc_id": "pwc:paper/pac-bayes-bounds-for-stable-algorithms-with", "entity_id": "pwc:method/svm", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [16408, 16411], "context_offset_in_paper": [16308, 16511], "context": "right hand side of our P@EW bound\ncomes from the concentration of the weight (see our concentration-SVM).\nLemma 1 of {{cite:8f445e6b-b58f-4865-b8ea-0389cab72565}}\nimplies a similar concentration inequali"}
{"id": "uxv:context/1806.06827-SVM-21248-21451", "type": "context", "paper_arxiv_id": "1806.06827", "paper_pwc_id": "pwc:paper/pac-bayes-bounds-for-stable-algorithms-with", "entity_id": "pwc:method/svm", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [21348, 21351], "context_offset_in_paper": [21248, 21451], "context": "entration of the weight vector\nFORMULA .\nCorollary 9 \nLet FORMULA .\nSuppose that the kernel used by SVM is bounded by FORMULA .\n[size=,color=blue!20!white,]Csaba: This was messed up. I think FORMULA  is "}
{"id": "uxv:context/1806.06827-SVM-22476-22679", "type": "context", "paper_arxiv_id": "1806.06827", "paper_pwc_id": "pwc:paper/pac-bayes-bounds-for-stable-algorithms-with", "entity_id": "pwc:method/svm", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [22576, 22579], "context_offset_in_paper": [22476, 22679], "context": "ace), and FORMULA , respectively.\nFIGURE \nFIGURE \nModel and data preparation We used an offset-free SVM classifier\nwith a Gaussian RBF kernel FORMULA \nwith RBF width parameter FORMULA .\nThe SVM used the "}
{"id": "uxv:context/1806.06827-SVM-22566-22769", "type": "context", "paper_arxiv_id": "1806.06827", "paper_pwc_id": "pwc:paper/pac-bayes-bounds-for-stable-algorithms-with", "entity_id": "pwc:method/svm", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [22666, 22669], "context_offset_in_paper": [22566, 22769], "context": "fset-free SVM classifier\nwith a Gaussian RBF kernel FORMULA \nwith RBF width parameter FORMULA .\nThe SVM used the so-called standard SVM-C formulation;\nthe conversion between our and the SVM-C formulation"}
{"id": "uxv:context/1806.06827-SVM-22598-22801", "type": "context", "paper_arxiv_id": "1806.06827", "paper_pwc_id": "pwc:paper/pac-bayes-bounds-for-stable-algorithms-with", "entity_id": "pwc:method/svm", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [22698, 22701], "context_offset_in_paper": [22598, 22801], "context": "Gaussian RBF kernel FORMULA \nwith RBF width parameter FORMULA .\nThe SVM used the so-called standard SVM-C formulation;\nthe conversion between our and the SVM-C formulation which multiplies\nthe total (hin"}
{"id": "uxv:context/1806.06827-SVM-22652-22855", "type": "context", "paper_arxiv_id": "1806.06827", "paper_pwc_id": "pwc:paper/pac-bayes-bounds-for-stable-algorithms-with", "entity_id": "pwc:method/svm", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [22752, 22755], "context_offset_in_paper": [22652, 22855], "context": "FORMULA .\nThe SVM used the so-called standard SVM-C formulation;\nthe conversion between our and the SVM-C formulation which multiplies\nthe total (hinge) loss by FORMULA  is given by FORMULA \nwhere FORMUL"}
{"id": "uxv:context/1806.06827-SVM-24178-24381", "type": "context", "paper_arxiv_id": "1806.06827", "paper_pwc_id": "pwc:paper/pac-bayes-bounds-for-stable-algorithms-with", "entity_id": "pwc:method/svm", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [24278, 24281], "context_offset_in_paper": [24178, 24381], "context": "ved to be close to one.\nComputations\nFor each of the FORMULA  pairs on the said grid, we trained an SVM-model using a Python implementation of the SMO algorithm of {{cite:bbeca3f2-fd15-42f2-ace0-d154f312"}
{"id": "uxv:context/1806.06827-SVM-24301-24504", "type": "context", "paper_arxiv_id": "1806.06827", "paper_pwc_id": "pwc:paper/pac-bayes-bounds-for-stable-algorithms-with", "entity_id": "pwc:method/svm", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [24401, 24404], "context_offset_in_paper": [24301, 24504], "context": "n implementation of the SMO algorithm of {{cite:bbeca3f2-fd15-42f2-ace0-d154f3127853}}, adjusted to SVMs with no offset ( argue that \u201cthe offset term has neither a known theoretical nor an empirical adva"}
{"id": "uxv:context/1806.06827-SVM-24639-24842", "type": "context", "paper_arxiv_id": "1806.06827", "paper_pwc_id": "pwc:paper/pac-bayes-bounds-for-stable-algorithms-with", "entity_id": "pwc:method/svm", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [24739, 24742], "context_offset_in_paper": [24639, 24842], "context": "r rates (recall that the randomized classifiers' test error is different than the test error of the SVM model that uses no randomization).\nThe bounds compared were the two mentioned hinge-loss based boun"}
{"id": "uxv:context/1806.06827-SVM-28776-28979", "type": "context", "paper_arxiv_id": "1806.06827", "paper_pwc_id": "pwc:paper/pac-bayes-bounds-for-stable-algorithms-with", "entity_id": "pwc:method/svm", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [28876, 28879], "context_offset_in_paper": [28776, 28979], "context": "g the stability of the hypothesis\nlearned by a Hilbert space valued algorithm. A special case being SVMs.\nWe applied our main theorem to SVMs, leading to our P@EW bound,\nand we compared it to other stabi"}
{"id": "uxv:context/1806.06827-SVM-28813-29016", "type": "context", "paper_arxiv_id": "1806.06827", "paper_pwc_id": "pwc:paper/pac-bayes-bounds-for-stable-algorithms-with", "entity_id": "pwc:method/svm", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [28913, 28916], "context_offset_in_paper": [28813, 29016], "context": "rned by a Hilbert space valued algorithm. A special case being SVMs.\nWe applied our main theorem to SVMs, leading to our P@EW bound,\nand we compared it to other stability-based bounds and to a\npreviously"}
{"id": "uxv:context/1806.06827-SVM-32576-32779", "type": "context", "paper_arxiv_id": "1806.06827", "paper_pwc_id": "pwc:paper/pac-bayes-bounds-for-stable-algorithms-with", "entity_id": "pwc:method/svm", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [32676, 32679], "context_offset_in_paper": [32576, 32779], "context": "dicular to FORMULA .\nSuch FORMULA  is a Gaussian centered at FORMULA ,\ngiving his formula\nFORMULA \n\nSVM weight vector: clarification about formulations\nWe have a sample of size FORMULA .\nIn the standard "}
{"id": "uxv:context/1806.06827-SVM-37546-37749", "type": "context", "paper_arxiv_id": "1806.06827", "paper_pwc_id": "pwc:paper/pac-bayes-bounds-for-stable-algorithms-with", "entity_id": "pwc:method/svm", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [37646, 37649], "context_offset_in_paper": [37546, 37749], "context": ".\nPredicting with the Gaussian random classifier\nLet FORMULA  be the weight vector found\nby running SVM on the sample FORMULA .\nWe write it as FORMULA .\nAlso as above let FORMULA  be a Gaussian random ve"}
{"id": "uxv:context/1806.06811-ImageNet-3285-3493", "type": "context", "paper_arxiv_id": "1806.06811", "paper_pwc_id": "pwc:paper/temporal-coherence-based-self-supervised", "entity_id": "pwc:dataset/imagenet", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [3385, 3393], "context_offset_in_paper": [3285, 3493], "context": "m afterwards.\nOften, networks are pretrained using labeled data coming from another domain, such as ImageNet\u00a0{{cite:93eeb0cb-aeff-41d4-b823-21a5e9520f6b}}.\nAnother way is to use unlabeled data from the same d"}
{"id": "uxv:context/1806.06811-ImageNet-6609-6817", "type": "context", "paper_arxiv_id": "1806.06811", "paper_pwc_id": "pwc:paper/temporal-coherence-based-self-supervised", "entity_id": "pwc:dataset/imagenet", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [6709, 6717], "context_offset_in_paper": [6609, 6817], "context": "egmentation is a ResNet-50 CNN {{cite:ea792643-0889-4776-8754-b693554341aa}}. We initialize it with ImageNet\u00a0{{cite:93eeb0cb-aeff-41d4-b823-21a5e9520f6b}} pretrained weights and further train it on unlabeled "}
{"id": "uxv:context/1806.06811-ImageNet-8247-8455", "type": "context", "paper_arxiv_id": "1806.06811", "paper_pwc_id": "pwc:paper/temporal-coherence-based-self-supervised", "entity_id": "pwc:dataset/imagenet", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [8347, 8355], "context_offset_in_paper": [8247, 8455], "context": " fully connected layer with FORMULA  output neurons (FeatureNet).\nAs the CNN has been pretrained on ImageNet, we only adjust the weights of the conv5_x layers and of the newly added fully connected layer duri"}
{"id": "uxv:context/1806.06811-ImageNet-13370-13578", "type": "context", "paper_arxiv_id": "1806.06811", "paper_pwc_id": "pwc:paper/temporal-coherence-based-self-supervised", "entity_id": "pwc:dataset/imagenet", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [13470, 13478], "context_offset_in_paper": [13370, 13578], "context": " fine-tuned in the same manner.\nNote that the underlying ResNet-50 CNN had still been pretrained on ImageNet.\nFor fine-tuning the networks, we used the Adam optimizer {{cite:60044919-7293-4921-9b65-49009bf068"}
{"id": "uxv:context/1806.06811-Cholec80-1312-1520", "type": "context", "paper_arxiv_id": "1806.06811", "paper_pwc_id": "pwc:paper/temporal-coherence-based-self-supervised", "entity_id": "pwc:dataset/cholec80", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [1412, 1420], "context_offset_in_paper": [1312, 1520], "context": "s on unlabeled laparoscopic videos using temporal coherence.\nWe evaluate our pretrained networks on Cholec80, a publicly available dataset for surgical phase segmentation, on which a maximum FORMULA  score of"}
{"id": "uxv:context/1806.06811-Cholec80-6047-6255", "type": "context", "paper_arxiv_id": "1806.06811", "paper_pwc_id": "pwc:paper/temporal-coherence-based-self-supervised", "entity_id": "pwc:dataset/cholec80", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [6147, 6155], "context_offset_in_paper": [6047, 6255], "context": " we made our code available at https://gitlab.com/nct_tso_public/pretrain_tc.\nExperiments using the Cholec80 dataset {{cite:0864ea5e-5508-4eef-a4b4-81b32845d007}} demonstrate that a CNN pretrained to exploit "}
{"id": "uxv:context/1806.06811-Cholec80-11656-11864", "type": "context", "paper_arxiv_id": "1806.06811", "paper_pwc_id": "pwc:paper/temporal-coherence-based-self-supervised", "entity_id": "pwc:dataset/cholec80", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [11756, 11764], "context_offset_in_paper": [11656, 11864], "context": "Net-50 layers below conv5_x stay frozen.\n\nEvaluation\nFor evaluation, we used the publicly available Cholec80 dataset {{cite:0864ea5e-5508-4eef-a4b4-81b32845d007}}. It consists of 80 videos from laparoscopic c"}
{"id": "uxv:context/1806.06811-Self-Supervised Learning-0-196", "type": "context", "paper_arxiv_id": "1806.06811", "paper_pwc_id": "pwc:paper/temporal-coherence-based-self-supervised", "entity_id": "pwc:task/self-supervised-learning", "entity_offset_in_context": [72, -100], "entity_offset_in_paper": [72, 96], "context_offset_in_paper": [0, 196], "context": "\n2pt plus 1pt minus 1pt\n2pt plus 1pt minus 1pt\nTemporal coherence-based self-supervised learning for laparoscopic workflow analysis\nTemporal coherence-based self-supervised learning for lap. workf"}
{"id": "uxv:context/1806.06811-Self-Supervised Learning-57-281", "type": "context", "paper_arxiv_id": "1806.06811", "paper_pwc_id": "pwc:paper/temporal-coherence-based-self-supervised", "entity_id": "pwc:task/self-supervised-learning", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [157, 181], "context_offset_in_paper": [57, 281], "context": "oherence-based self-supervised learning for laparoscopic workflow analysis\nTemporal coherence-based self-supervised learning for lap. workflow analysis\nIsabel Funke1Both authors contributed equally to this work. Alexander Je"}
{"id": "uxv:context/1806.06811-Self-Supervised Learning-1579-1803", "type": "context", "paper_arxiv_id": "1806.06811", "paper_pwc_id": "pwc:paper/temporal-coherence-based-self-supervised", "entity_id": "pwc:task/self-supervised-learning", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [1679, 1703], "context_offset_in_paper": [1579, 1803], "context": "increase of the FORMULA  score of up to 10 points when compared to a non-pretrained neural network.\nself-supervised learning temporal coherence surgical workflow analysis surgical phase recognition pretraining CNN-LSTM.\nIntr"}
{"id": "uxv:context/1806.06811-Self-Supervised Learning-3476-3700", "type": "context", "paper_arxiv_id": "1806.06811", "paper_pwc_id": "pwc:paper/temporal-coherence-based-self-supervised", "entity_id": "pwc:task/self-supervised-learning", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [3576, 3600], "context_offset_in_paper": [3476, 3700], "context": "a from the same domain and train on a proxy task using labels inherent in the data, which is called self-supervised learning.\nFor self-supervised learning from video, a number of ideas have been proposed\u00a0{{cite:f7b7368d-2809"}
{"id": "uxv:context/1806.06811-Self-Supervised Learning-3506-3730", "type": "context", "paper_arxiv_id": "1806.06811", "paper_pwc_id": "pwc:paper/temporal-coherence-based-self-supervised", "entity_id": "pwc:task/self-supervised-learning", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [3606, 3630], "context_offset_in_paper": [3506, 3730], "context": "in on a proxy task using labels inherent in the data, which is called self-supervised learning.\nFor self-supervised learning from video, a number of ideas have been proposed\u00a0{{cite:f7b7368d-2809-4165-b163-7540f1c50309}}, {{c"}
{"id": "uxv:context/1806.06811-Self-Supervised Learning-6783-7007", "type": "context", "paper_arxiv_id": "1806.06811", "paper_pwc_id": "pwc:paper/temporal-coherence-based-self-supervised", "entity_id": "pwc:task/self-supervised-learning", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [6883, 6907], "context_offset_in_paper": [6783, 7007], "context": "and further train it on unlabeled videos of laparoscopic surgeries, using an SFA-based approach for self-supervised learning.\nThis encourages the CNN to map temporally close video frames to similar representations in feature"}
{"id": "uxv:context/1806.00187-Machine Translation-1026-1245", "type": "context", "paper_arxiv_id": "1806.00187", "paper_pwc_id": "pwc:paper/scaling-neural-machine-translation", "entity_id": "pwc:task/machine-translation", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [1126, 1145], "context_offset_in_paper": [1026, 1245], "context": "rench task, we obtain a state-of-the-art BLEU of 43.2 in 8.5 hours on 128 GPUs.\nIntroduction\nNeural Machine Translation (NMT) has seen impressive progress in the recent years with the introduction of ever more efficient"}
{"id": "uxv:context/1806.00187-Machine Translation-5160-5379", "type": "context", "paper_arxiv_id": "1806.00187", "paper_pwc_id": "pwc:paper/scaling-neural-machine-translation", "entity_id": "pwc:task/machine-translation", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [5260, 5279], "context_offset_in_paper": [5160, 5379], "context": "s over multiple machines and then performs a synchronized update of the model weights. Large neural machine translation systems have been recently trained with this algorithm with success\u00a0{{cite:cb6741ec-4ac1-4acc-80a5-"}
{"id": "uxv:context/1806.00187-Translation-589-800", "type": "context", "paper_arxiv_id": "1806.00187", "paper_pwc_id": "pwc:paper/scaling-neural-machine-translation", "entity_id": "pwc:task/translation", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [689, 700], "context_offset_in_paper": [589, 800], "context": "ur implementation is available at:\nhttps://www.github.com/pytorch/fairseq\n\nOn WMT'14 English-German translation, we match the accuracy of {{cite:8d2bdf87-f11e-40a2-adb8-89a437a3829e}} in under 5 hours when train"}
{"id": "uxv:context/1806.00187-Translation-1034-1245", "type": "context", "paper_arxiv_id": "1806.00187", "paper_pwc_id": "pwc:paper/scaling-neural-machine-translation", "entity_id": "pwc:task/translation", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [1134, 1145], "context_offset_in_paper": [1034, 1245], "context": "sk, we obtain a state-of-the-art BLEU of 43.2 in 8.5 hours on 128 GPUs.\nIntroduction\nNeural Machine Translation (NMT) has seen impressive progress in the recent years with the introduction of ever more efficient"}
{"id": "uxv:context/1806.00187-Translation-5168-5379", "type": "context", "paper_arxiv_id": "1806.00187", "paper_pwc_id": "pwc:paper/scaling-neural-machine-translation", "entity_id": "pwc:task/translation", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [5268, 5279], "context_offset_in_paper": [5168, 5379], "context": "ultiple machines and then performs a synchronized update of the model weights. Large neural machine translation systems have been recently trained with this algorithm with success\u00a0{{cite:cb6741ec-4ac1-4acc-80a5-"}
{"id": "uxv:context/1806.06793-3D Convolution-661-875", "type": "context", "paper_arxiv_id": "1806.06793", "paper_pwc_id": "pwc:paper/deep-spatiotemporal-representation-of-the", "entity_id": "pwc:method/3d-convolution", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [761, 775], "context_offset_in_paper": [661, 875], "context": "e proposed model is built by stacking several convolutional modules where each module encompasses a 3D convolution kernel with a fixed temporal depth, several parallel 3D convolutional kernels with different tempor"}
{"id": "uxv:context/1806.06793-3D Convolution-5302-5516", "type": "context", "paper_arxiv_id": "1806.06793", "paper_pwc_id": "pwc:paper/deep-spatiotemporal-representation-of-the", "entity_id": "pwc:method/3d-convolution", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [5402, 5416], "context_offset_in_paper": [5302, 5516], "context": "xplored 3D CNNs with a kernel size of FORMULA  to learn both the spatial and temporal features with 3D convolution operations. Sun et al. {{cite:a06456f4-643e-40ce-a703-1750f0266b62}} decomposed 3D convolutions int"}
{"id": "uxv:context/1806.06793-3D Convolution-5397-5611", "type": "context", "paper_arxiv_id": "1806.06793", "paper_pwc_id": "pwc:paper/deep-spatiotemporal-representation-of-the", "entity_id": "pwc:method/3d-convolution", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [5497, 5511], "context_offset_in_paper": [5397, 5611], "context": "with 3D convolution operations. Sun et al. {{cite:a06456f4-643e-40ce-a703-1750f0266b62}} decomposed 3D convolutions into 2D spatial and 1D temporal convolutions. Carreira et al. {{cite:a8ad31f3-3ca5-41f0-b0c3-d6f45"}
{"id": "uxv:context/1806.06793-3D Convolution-5809-6023", "type": "context", "paper_arxiv_id": "1806.06793", "paper_pwc_id": "pwc:paper/deep-spatiotemporal-representation-of-the", "entity_id": "pwc:method/3d-convolution", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [5909, 5923], "context_offset_in_paper": [5809, 6023], "context": "his by repeating the weights of 2D filters FORMULA  times. All these structures have fixed temporal 3D convolution kernel depths throughout the whole architecture, that make them incapable of capturing short, mid, "}
{"id": "uxv:context/1806.06793-3D Convolution-7783-7997", "type": "context", "paper_arxiv_id": "1806.06793", "paper_pwc_id": "pwc:paper/deep-spatiotemporal-representation-of-the", "entity_id": "pwc:method/3d-convolution", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [7883, 7897], "context_offset_in_paper": [7783, 7997], "context": "kernels are simply concatenated and fed to an average pooling layer.\nThe output feature maps of the 3D convolutions and pooling kernels at the FORMULA -th convolutional module extracted from an input FORMULA  is a "}
{"id": "uxv:context/1806.06793-3D Convolution-11906-12120", "type": "context", "paper_arxiv_id": "1806.06793", "paper_pwc_id": "pwc:paper/deep-spatiotemporal-representation-of-the", "entity_id": "pwc:method/3d-convolution", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [12006, 12020], "context_offset_in_paper": [11906, 12120], "context": "ve convolutional modules (see Section ). In each architecture, we change the number of the parallel 3D convolution kernels to determine the appropriate temporal range that is required to be captured. Figure REF  sh"}
{"id": "uxv:context/1806.06793-3D Convolution-12231-12445", "type": "context", "paper_arxiv_id": "1806.06793", "paper_pwc_id": "pwc:paper/deep-spatiotemporal-representation-of-the", "entity_id": "pwc:method/3d-convolution", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [12331, 12345], "context_offset_in_paper": [12231, 12445], "context": "nvolution kernels. It can be seen that the highest accuracy is obtained when the number of parallel 3D convolutions and the model's depth are set to 3 and 17, respectively. Therefore, our model has 53 layers includ"}
{"id": "uxv:context/1806.06793-3D Convolution-12438-12652", "type": "context", "paper_arxiv_id": "1806.06793", "paper_pwc_id": "pwc:paper/deep-spatiotemporal-representation-of-the", "entity_id": "pwc:method/3d-convolution", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [12538, 12552], "context_offset_in_paper": [12438, 12652], "context": " including convolution, average pooling, and fully connected layers. In our framework, the parallel 3D convolutions of each module are considered as one layer, as their input is the same and their output feature ma"}
{"id": "uxv:context/1806.06793-3D Convolution-16453-16667", "type": "context", "paper_arxiv_id": "1806.06793", "paper_pwc_id": "pwc:paper/deep-spatiotemporal-representation-of-the", "entity_id": "pwc:method/3d-convolution", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [16553, 16567], "context_offset_in_paper": [16453, 16667], "context": "emporal information of spontaneous variations in the face expression by exploiting several parallel 3D convolution operations with divers temporal depths. Unlike 3D convolutional neural networks with fixed 3D homog"}
{"id": "uxv:context/1806.06793-Average Pooling-793-1008", "type": "context", "paper_arxiv_id": "1806.06793", "paper_pwc_id": "pwc:paper/deep-spatiotemporal-representation-of-the", "entity_id": "pwc:method/average-pooling", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [893, 908], "context_offset_in_paper": [793, 1008], "context": "ed temporal depth, several parallel 3D convolutional kernels with different temporal depths, and an average pooling layer. Deploying variable temporal depths in the proposed architecture allows the model to effectiv"}
{"id": "uxv:context/1806.06793-Average Pooling-7729-7944", "type": "context", "paper_arxiv_id": "1806.06793", "paper_pwc_id": "pwc:paper/deep-spatiotemporal-representation-of-the", "entity_id": "pwc:method/average-pooling", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [7829, 7844], "context_offset_in_paper": [7729, 7944], "context": "presentation. The output of parallel 3D convolutional kernels are simply concatenated and fed to an average pooling layer.\nThe output feature maps of the 3D convolutions and pooling kernels at the FORMULA -th convol"}
{"id": "uxv:context/1806.06793-Average Pooling-8795-9010", "type": "context", "paper_arxiv_id": "1806.06793", "paper_pwc_id": "pwc:paper/deep-spatiotemporal-representation-of-the", "entity_id": "pwc:method/average-pooling", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [8895, 8910], "context_offset_in_paper": [8795, 9010], "context": "rnels (see the red arrows in Figure REF ). The function FORMULA  represents all the convolution and average pooling operations that are done in each module and defined as:\nFORMULA \nwhere FORMULA  denotes the ReLu no"}
{"id": "uxv:context/1806.06793-Average Pooling-8986-9201", "type": "context", "paper_arxiv_id": "1806.06793", "paper_pwc_id": "pwc:paper/deep-spatiotemporal-representation-of-the", "entity_id": "pwc:method/average-pooling", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [9086, 9101], "context_offset_in_paper": [8986, 9201], "context": "ULA  denotes the ReLu non-linearty and FORMULA  stands for concatenation operation. FORMULA  is the average pooling operator.\nWithin each convolutional module, after convolving the feature map of the preceding layer"}
{"id": "uxv:context/1806.06793-Average Pooling-9537-9752", "type": "context", "paper_arxiv_id": "1806.06793", "paper_pwc_id": "pwc:paper/deep-spatiotemporal-representation-of-the", "entity_id": "pwc:method/average-pooling", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [9637, 9652], "context_offset_in_paper": [9537, 9752], "context": "rmediate feature maps FORMULA  are simply concatenated into a single 3D tensor and then fed into an average pooling layer. As shown in Figure REF , the entire of the model are trained in an end-to-end network traini"}
{"id": "uxv:context/1806.06793-Average Pooling-12362-12577", "type": "context", "paper_arxiv_id": "1806.06793", "paper_pwc_id": "pwc:paper/deep-spatiotemporal-representation-of-the", "entity_id": "pwc:method/average-pooling", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [12462, 12477], "context_offset_in_paper": [12362, 12577], "context": " depth are set to 3 and 17, respectively. Therefore, our model has 53 layers including convolution, average pooling, and fully connected layers. In our framework, the parallel 3D convolutions of each module are cons"}
{"id": "uxv:context/1806.06793-Convolution-664-875", "type": "context", "paper_arxiv_id": "1806.06793", "paper_pwc_id": "pwc:paper/deep-spatiotemporal-representation-of-the", "entity_id": "pwc:method/convolution", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [764, 775], "context_offset_in_paper": [664, 875], "context": "roposed model is built by stacking several convolutional modules where each module encompasses a 3D convolution kernel with a fixed temporal depth, several parallel 3D convolutional kernels with different tempor"}
{"id": "uxv:context/1806.06793-Convolution-5305-5516", "type": "context", "paper_arxiv_id": "1806.06793", "paper_pwc_id": "pwc:paper/deep-spatiotemporal-representation-of-the", "entity_id": "pwc:method/convolution", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [5405, 5416], "context_offset_in_paper": [5305, 5516], "context": "ored 3D CNNs with a kernel size of FORMULA  to learn both the spatial and temporal features with 3D convolution operations. Sun et al. {{cite:a06456f4-643e-40ce-a703-1750f0266b62}} decomposed 3D convolutions int"}
{"id": "uxv:context/1806.06793-Convolution-5400-5611", "type": "context", "paper_arxiv_id": "1806.06793", "paper_pwc_id": "pwc:paper/deep-spatiotemporal-representation-of-the", "entity_id": "pwc:method/convolution", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [5500, 5511], "context_offset_in_paper": [5400, 5611], "context": "h 3D convolution operations. Sun et al. {{cite:a06456f4-643e-40ce-a703-1750f0266b62}} decomposed 3D convolutions into 2D spatial and 1D temporal convolutions. Carreira et al. {{cite:a8ad31f3-3ca5-41f0-b0c3-d6f45"}
{"id": "uxv:context/1806.06793-Convolution-5445-5656", "type": "context", "paper_arxiv_id": "1806.06793", "paper_pwc_id": "pwc:paper/deep-spatiotemporal-representation-of-the", "entity_id": "pwc:method/convolution", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [5545, 5556], "context_offset_in_paper": [5445, 5656], "context": "e:a06456f4-643e-40ce-a703-1750f0266b62}} decomposed 3D convolutions into 2D spatial and 1D temporal convolutions. Carreira et al. {{cite:a8ad31f3-3ca5-41f0-b0c3-d6f45f2cfe72}} proposed converting a pre-trained I"}
{"id": "uxv:context/1806.06793-Convolution-5812-6023", "type": "context", "paper_arxiv_id": "1806.06793", "paper_pwc_id": "pwc:paper/deep-spatiotemporal-representation-of-the", "entity_id": "pwc:method/convolution", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [5912, 5923], "context_offset_in_paper": [5812, 6023], "context": " by repeating the weights of 2D filters FORMULA  times. All these structures have fixed temporal 3D convolution kernel depths throughout the whole architecture, that make them incapable of capturing short, mid, "}
{"id": "uxv:context/1806.06793-Convolution-7786-7997", "type": "context", "paper_arxiv_id": "1806.06793", "paper_pwc_id": "pwc:paper/deep-spatiotemporal-representation-of-the", "entity_id": "pwc:method/convolution", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [7886, 7897], "context_offset_in_paper": [7786, 7997], "context": "nels are simply concatenated and fed to an average pooling layer.\nThe output feature maps of the 3D convolutions and pooling kernels at the FORMULA -th convolutional module extracted from an input FORMULA  is a "}
{"id": "uxv:context/1806.06793-Convolution-8779-8990", "type": "context", "paper_arxiv_id": "1806.06793", "paper_pwc_id": "pwc:paper/deep-spatiotemporal-representation-of-the", "entity_id": "pwc:method/convolution", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [8879, 8890], "context_offset_in_paper": [8779, 8990], "context": "convolutional kernels (see the red arrows in Figure REF ). The function FORMULA  represents all the convolution and average pooling operations that are done in each module and defined as:\nFORMULA \nwhere FORMULA "}
{"id": "uxv:context/1806.06793-Convolution-9126-9337", "type": "context", "paper_arxiv_id": "1806.06793", "paper_pwc_id": "pwc:paper/deep-spatiotemporal-representation-of-the", "entity_id": "pwc:method/convolution", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [9226, 9237], "context_offset_in_paper": [9126, 9337], "context": "nvolutional module, after convolving the feature map of the preceding layer FORMULA  with the first convolution kernel, FORMULA  intermediate feature maps FORMULA  are obtained, where FORMULA . Each intermediate"}
{"id": "uxv:context/1806.06793-Convolution-9309-9520", "type": "context", "paper_arxiv_id": "1806.06793", "paper_pwc_id": "pwc:paper/deep-spatiotemporal-representation-of-the", "entity_id": "pwc:method/convolution", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [9409, 9420], "context_offset_in_paper": [9309, 9520], "context": " FORMULA . Each intermediate feature map has a different number of channels as they are obtained by convolution operations of different temporal depths, while the spatial size of all feature maps FORMULA  is the"}
{"id": "uxv:context/1806.06793-Convolution-11909-12120", "type": "context", "paper_arxiv_id": "1806.06793", "paper_pwc_id": "pwc:paper/deep-spatiotemporal-representation-of-the", "entity_id": "pwc:method/convolution", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [12009, 12020], "context_offset_in_paper": [11909, 12120], "context": "convolutional modules (see Section ). In each architecture, we change the number of the parallel 3D convolution kernels to determine the appropriate temporal range that is required to be captured. Figure REF  sh"}
{"id": "uxv:context/1806.06793-Convolution-12129-12340", "type": "context", "paper_arxiv_id": "1806.06793", "paper_pwc_id": "pwc:paper/deep-spatiotemporal-representation-of-the", "entity_id": "pwc:method/convolution", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [12229, 12240], "context_offset_in_paper": [12129, 12340], "context": "ormalized accuracy of the proposed method for different network sizes and the number of 3D parallel convolution kernels. It can be seen that the highest accuracy is obtained when the number of parallel 3D convol"}
{"id": "uxv:context/1806.06793-Convolution-12234-12445", "type": "context", "paper_arxiv_id": "1806.06793", "paper_pwc_id": "pwc:paper/deep-spatiotemporal-representation-of-the", "entity_id": "pwc:method/convolution", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [12334, 12345], "context_offset_in_paper": [12234, 12445], "context": "lution kernels. It can be seen that the highest accuracy is obtained when the number of parallel 3D convolutions and the model's depth are set to 3 and 17, respectively. Therefore, our model has 53 layers includ"}
{"id": "uxv:context/1806.06793-Convolution-12349-12560", "type": "context", "paper_arxiv_id": "1806.06793", "paper_pwc_id": "pwc:paper/deep-spatiotemporal-representation-of-the", "entity_id": "pwc:method/convolution", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [12449, 12460], "context_offset_in_paper": [12349, 12560], "context": "d the model's depth are set to 3 and 17, respectively. Therefore, our model has 53 layers including convolution, average pooling, and fully connected layers. In our framework, the parallel 3D convolutions of eac"}
{"id": "uxv:context/1806.06793-Convolution-12441-12652", "type": "context", "paper_arxiv_id": "1806.06793", "paper_pwc_id": "pwc:paper/deep-spatiotemporal-representation-of-the", "entity_id": "pwc:method/convolution", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [12541, 12552], "context_offset_in_paper": [12441, 12652], "context": "cluding convolution, average pooling, and fully connected layers. In our framework, the parallel 3D convolutions of each module are considered as one layer, as their input is the same and their output feature ma"}
{"id": "uxv:context/1806.06793-Convolution-16456-16667", "type": "context", "paper_arxiv_id": "1806.06793", "paper_pwc_id": "pwc:paper/deep-spatiotemporal-representation-of-the", "entity_id": "pwc:method/convolution", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [16556, 16567], "context_offset_in_paper": [16456, 16667], "context": "oral information of spontaneous variations in the face expression by exploiting several parallel 3D convolution operations with divers temporal depths. Unlike 3D convolutional neural networks with fixed 3D homog"}
{"id": "uxv:context/1806.06784-regression-331-541", "type": "context", "paper_arxiv_id": "1806.06784", "paper_pwc_id": "pwc:paper/flexible-collaborative-estimation-of-the", "entity_id": "pwc:task/regression", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [431, 441], "context_offset_in_paper": [331, 541], "context": "average effect of a treatment on an outcome require estimation of the propensity score, the outcome regression, or both. It is often beneficial to utilize flexible techniques such as semiparametric regression o"}
{"id": "uxv:context/1806.06784-regression-429-639", "type": "context", "paper_arxiv_id": "1806.06784", "paper_pwc_id": "pwc:paper/flexible-collaborative-estimation-of-the", "entity_id": "pwc:task/regression", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [529, 539], "context_offset_in_paper": [429, 639], "context": "e regression, or both. It is often beneficial to utilize flexible techniques such as semiparametric regression or machine learning to estimate these quantities. However, optimal estimation of these regressions "}
{"id": "uxv:context/1806.06784-regression-527-737", "type": "context", "paper_arxiv_id": "1806.06784", "paper_pwc_id": "pwc:paper/flexible-collaborative-estimation-of-the", "entity_id": "pwc:task/regression", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [627, 637], "context_offset_in_paper": [527, 737], "context": "c regression or machine learning to estimate these quantities. However, optimal estimation of these regressions does not necessarily lead to optimal estimation of the average treatment effect, particularly in s"}
{"id": "uxv:context/1806.06784-regression-766-976", "type": "context", "paper_arxiv_id": "1806.06784", "paper_pwc_id": "pwc:paper/flexible-collaborative-estimation-of-the", "entity_id": "pwc:task/regression", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [866, 876], "context_offset_in_paper": [766, 976], "context": "tal variables. A recent proposal addressed these issues via the outcome-adaptive lasso, a penalized regression technique for estimating the propensity score that seeks to minimize the impact of instrumental var"}
{"id": "uxv:context/1806.06784-regression-1975-2185", "type": "context", "paper_arxiv_id": "1806.06784", "paper_pwc_id": "pwc:paper/flexible-collaborative-estimation-of-the", "entity_id": "pwc:task/regression", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [2075, 2085], "context_offset_in_paper": [1975, 2185], "context": "nt {{cite:b8504acf-c418-4d39-927c-41efb982bfc8}}. These differences are often accounted for through regression adjustment, either through estimation of the mean outcome given treatment and confounders (the outc"}
{"id": "uxv:context/1806.06784-regression-2089-2299", "type": "context", "paper_arxiv_id": "1806.06784", "paper_pwc_id": "pwc:paper/flexible-collaborative-estimation-of-the", "entity_id": "pwc:task/regression", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [2189, 2199], "context_offset_in_paper": [2089, 2299], "context": "ustment, either through estimation of the mean outcome given treatment and confounders (the outcome regression), the probability of treatment given confounders (the propensity score), or both. Many popular tech"}
{"id": "uxv:context/1806.06784-regression-2293-2503", "type": "context", "paper_arxiv_id": "1806.06784", "paper_pwc_id": "pwc:paper/flexible-collaborative-estimation-of-the", "entity_id": "pwc:task/regression", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [2393, 2403], "context_offset_in_paper": [2293, 2503], "context": "r techniques for generating efficient estimates of the average treatment effect (ATE) utilize these regression estimates as an intermediate step. For example, the inverse probability of treatment weighted (IPTW"}
{"id": "uxv:context/1806.06784-regression-2608-2818", "type": "context", "paper_arxiv_id": "1806.06784", "paper_pwc_id": "pwc:paper/flexible-collaborative-estimation-of-the", "entity_id": "pwc:task/regression", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [2708, 2718], "context_offset_in_paper": [2608, 2818], "context": " observations receiving treatment. More involved procedures are available that use both the outcome regression and propensity score to generate an asymptotically efficient estimate of the average treatment effe"}
{"id": "uxv:context/1806.06784-regression-2904-3114", "type": "context", "paper_arxiv_id": "1806.06784", "paper_pwc_id": "pwc:paper/flexible-collaborative-estimation-of-the", "entity_id": "pwc:task/regression", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [3004, 3014], "context_offset_in_paper": [2904, 3114], "context": "hted (AIPTW) estimators and targeted minimum loss-based estimators (TMLEs).\nCommonly, the requisite regressions for estimation of the ATE are modeled using parametric techniques such as linear and logistic regr"}
{"id": "uxv:context/1806.06784-regression-3010-3220", "type": "context", "paper_arxiv_id": "1806.06784", "paper_pwc_id": "pwc:paper/flexible-collaborative-estimation-of-the", "entity_id": "pwc:task/regression", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [3110, 3120], "context_offset_in_paper": [3010, 3220], "context": "sions for estimation of the ATE are modeled using parametric techniques such as linear and logistic regression. However, misspecification of regression models can lead to extreme bias in estimates of the ATE {{"}
{"id": "uxv:context/1806.06784-regression-3051-3261", "type": "context", "paper_arxiv_id": "1806.06784", "paper_pwc_id": "pwc:paper/flexible-collaborative-estimation-of-the", "entity_id": "pwc:task/regression", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [3151, 3161], "context_offset_in_paper": [3051, 3261], "context": "ed using parametric techniques such as linear and logistic regression. However, misspecification of regression models can lead to extreme bias in estimates of the ATE {{cite:db17506d-daa3-484d-b982-ce03ba4bb146"}
{"id": "uxv:context/1806.06784-regression-3482-3692", "type": "context", "paper_arxiv_id": "1806.06784", "paper_pwc_id": "pwc:paper/flexible-collaborative-estimation-of-the", "entity_id": "pwc:task/regression", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [3582, 3592], "context_offset_in_paper": [3482, 3692], "context": ":95a851dd-2b0d-48dc-aeec-8923b58c99c1}}, {{cite:ffa5c822-1827-4eb9-834e-4853610c0844}} and adaptive regression techniques to estimate the ATE {{cite:157c1618-aa6c-4fc0-9a9a-88a8040e72fb}}, {{cite:84e601c3-10ce-"}
{"id": "uxv:context/1806.06784-regression-3956-4166", "type": "context", "paper_arxiv_id": "1806.06784", "paper_pwc_id": "pwc:paper/flexible-collaborative-estimation-of-the", "entity_id": "pwc:task/regression", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [4056, 4066], "context_offset_in_paper": [3956, 4166], "context": "stical inference about estimated treatment effects when machine learning techniques are used to fit regressions {{cite:b4879d4f-0293-4fef-943f-695a1494521d}}, {{cite:15f12bbf-95a0-4dcb-9b22-bc69bc3ac27b}}. A pa"}
{"id": "uxv:context/1806.06784-regression-4817-5027", "type": "context", "paper_arxiv_id": "1806.06784", "paper_pwc_id": "pwc:paper/flexible-collaborative-estimation-of-the", "entity_id": "pwc:task/regression", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [4917, 4927], "context_offset_in_paper": [4817, 5027], "context": "t including instrumental variables \u2013 variates that affect the propensity score, but not the outcome regression \u2013 in the propensity score leads to inflation of the variance of the estimator of the average treatm"}
{"id": "uxv:context/1806.06784-regression-5406-5616", "type": "context", "paper_arxiv_id": "1806.06784", "paper_pwc_id": "pwc:paper/flexible-collaborative-estimation-of-the", "entity_id": "pwc:task/regression", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [5506, 5516], "context_offset_in_paper": [5406, 5616], "context": "ariable selection in an estimate of propensity scores. The proposal involves estimating the outcome regression using a generalized linear model and using the coefficients from this fit as evidence of how strong"}
{"id": "uxv:context/1806.06784-regression-5790-6000", "type": "context", "paper_arxiv_id": "1806.06784", "paper_pwc_id": "pwc:paper/flexible-collaborative-estimation-of-the", "entity_id": "pwc:task/regression", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [5890, 5900], "context_offset_in_paper": [5790, 6000], "context": "d with each variable is proportional to the absolute value of the inverse of the variable's outcome regression coefficient. Thus, variables that are strongly related to the outcome (i.e., have a large coefficie"}
{"id": "uxv:context/1806.06784-regression-5918-6128", "type": "context", "paper_arxiv_id": "1806.06784", "paper_pwc_id": "pwc:paper/flexible-collaborative-estimation-of-the", "entity_id": "pwc:task/regression", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [6018, 6028], "context_offset_in_paper": [5918, 6128], "context": ", variables that are strongly related to the outcome (i.e., have a large coefficient in the outcome regression model) are penalized less, and are more likely to be included the propensity score. The resultant p"}
{"id": "uxv:context/1806.06784-regression-6349-6559", "type": "context", "paper_arxiv_id": "1806.06784", "paper_pwc_id": "pwc:paper/flexible-collaborative-estimation-of-the", "entity_id": "pwc:task/regression", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [6449, 6459], "context_offset_in_paper": [6349, 6559], "context": "posal of {{cite:0cc57231-0ef4-49a4-8e95-f1c5103b034e}}, but using HAL instead of parametric outcome regression and propensity score models. This seemingly straightforward extension turns out to have interesting"}
{"id": "uxv:context/1806.06784-regression-6846-7056", "type": "context", "paper_arxiv_id": "1806.06784", "paper_pwc_id": "pwc:paper/flexible-collaborative-estimation-of-the", "entity_id": "pwc:task/regression", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [6946, 6956], "context_offset_in_paper": [6846, 7056], "context": "functions, the set of infinitesimal indicator basis functions that may be excluded from the outcome regression while still capturing its true form. The second interesting implication of utilizing Shortreed's me"}
{"id": "uxv:context/1806.06784-regression-10768-10978", "type": "context", "paper_arxiv_id": "1806.06784", "paper_pwc_id": "pwc:paper/flexible-collaborative-estimation-of-the", "entity_id": "pwc:task/regression", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [10868, 10878], "context_offset_in_paper": [10768, 10978], "context": "ric approaches have been proposed for estimating the ATE that use flexible estimates of the outcome regression and propensity score. Targeted minimum loss-based estimation (TMLE) is one such example. For each p"}
{"id": "uxv:context/1806.06784-regression-10960-11170", "type": "context", "paper_arxiv_id": "1806.06784", "paper_pwc_id": "pwc:paper/flexible-collaborative-estimation-of-the", "entity_id": "pwc:task/regression", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [11060, 11070], "context_offset_in_paper": [10960, 11170], "context": "xample. For each possible FORMULA , we denote by FORMULA  an estimate of FORMULA , the true outcome regression at FORMULA . Similarly, we denote by FORMULA  an estimate of the propensity score FORMULA . Using t"}
{"id": "uxv:context/1806.06784-regression-11226-11436", "type": "context", "paper_arxiv_id": "1806.06784", "paper_pwc_id": "pwc:paper/flexible-collaborative-estimation-of-the", "entity_id": "pwc:task/regression", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [11326, 11336], "context_offset_in_paper": [11226, 11436], "context": "lar parametric working model. Because FORMULA , we may use a logistic working model for the outcome regression, FORMULA , where FORMULA  Note that this defines a logistic regression model with offset given by t"}
{"id": "uxv:context/1806.06784-regression-11297-11507", "type": "context", "paper_arxiv_id": "1806.06784", "paper_pwc_id": "pwc:paper/flexible-collaborative-estimation-of-the", "entity_id": "pwc:task/regression", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [11397, 11407], "context_offset_in_paper": [11297, 11507], "context": "orking model for the outcome regression, FORMULA , where FORMULA  Note that this defines a logistic regression model with offset given by the logit of the initial estimator and single covariate FORMULA . We als"}
{"id": "uxv:context/1806.06784-regression-12177-12387", "type": "context", "paper_arxiv_id": "1806.06784", "paper_pwc_id": "pwc:paper/flexible-collaborative-estimation-of-the", "entity_id": "pwc:task/regression", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [12277, 12287], "context_offset_in_paper": [12177, 12387], "context": ", a key object in efficiency theory {{cite:4c892a5d-86ad-405f-ba8f-e68bb4bb68b0}}. Given an outcome regression FORMULA , a propensity score FORMULA , and a marginal cumulative distribution function of FORMULA ,"}
{"id": "uxv:context/1806.06784-regression-12945-13155", "type": "context", "paper_arxiv_id": "1806.06784", "paper_pwc_id": "pwc:paper/flexible-collaborative-estimation-of-the", "entity_id": "pwc:task/regression", "entity_offset_in_context": [100, -100], "entity_offset_in_paper": [13045, 13055], "context_offset_in_paper": [12945, 13155], "context": ").\nWe denote by FORMULA  the empirical cumulative distribution function of FORMULA . If the outcome regression and propensity score estimators are such that FORMULA  falls in a FORMULA -Donsker class with proba"}
